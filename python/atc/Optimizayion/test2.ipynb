{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2803 - accuracy: 0.9217 - val_loss: 0.1149 - val_accuracy: 0.9690\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1063 - accuracy: 0.9690 - val_loss: 0.0769 - val_accuracy: 0.9798\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.0706 - val_accuracy: 0.9832\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0670 - accuracy: 0.9805 - val_loss: 0.0706 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2593f2717d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9768999814987183\n",
      "Saved baseline model to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpyedwmpf4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_25388\\237956268.py:7: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
      " e_1 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
      " _2 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
      " oling2d_2 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 2028)              1         \n",
      " n_1 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                40572     \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40805 (159.41 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 20395 (79.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 4s 7ms/step - loss: 0.1395 - accuracy: 0.9607 - val_loss: 0.1830 - val_accuracy: 0.9572\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.1469 - accuracy: 0.9638 - val_loss: 0.1084 - val_accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25984fc1ed0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9768999814987183\n",
      "Pruned test accuracy: 0.9660999774932861\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_25388\\1300288761.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpuhlqagf4.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp20xwe11e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp20xwe11e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpaqhrsw4s.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_4 (Quantize  (None, 28, 28)            3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_reshape_1 (QuantizeW  (None, 28, 28, 1)         1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_2 (QuantizeWr  (None, 26, 26, 12)        147       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_2 (Qua  (None, 13, 13, 12)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_1 (QuantizeW  (None, 2028)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_3 (QuantizeWra  (None, 10)                20295     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20448 (79.88 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 38 (152.00 Byte)\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.1172 - accuracy: 0.9678 - val_loss: 0.1800 - val_accuracy: 0.9600\n",
      "Baseline test accuracy: 0.9660999774932861\n",
      "Quant test accuracy: 0.964900016784668\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpo_ghd4uz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpo_ghd4uz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1250 - accuracy: 0.9649\n",
      "양자화 모델 정확성: 0.964900016784668\n"
     ]
    }
   ],
   "source": [
    "# 양자화 함수 정의\n",
    "def apply_quantization_to_loaded_model(loaded_model):\n",
    "    quantize_model = tfmot.quantization.keras.quantize_model(loaded_model)\n",
    "    quantize_model.compile(optimizer='adam',\n",
    "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           metrics=['accuracy'])\n",
    "    return quantize_model\n",
    "\n",
    "# 양자화 모델 생성\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()\n",
    "\n",
    "train_images_subset = train_images[0:1000] # out of 60000\n",
    "train_labels_subset = train_labels[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                  batch_size=500, epochs=1, validation_split=0.1)\n",
    "\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "# TFLite 변환 (가지치기 모델을 양자화 모델로 변환)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# TFLite 모델 저장\n",
    "with open(\"quantized_model.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# 양자화 모델 평가\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"양자화 모델 정확성:\", q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성능 비교:\n",
      "원본 모델 정확성: 0.9886999726295471\n",
      "가지치기 모델 정확성: 0.9660999774932861\n",
      "양자화 모델 정확성: 0.11349999904632568\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# 모델 크기 비교\u001b[39;00m\n\u001b[0;32m      8\u001b[0m original_model_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(loaded_model\u001b[39m.\u001b[39mto_json())\n\u001b[1;32m----> 9\u001b[0m pruned_model_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pruned_keras_file\u001b[39m.\u001b[39;49mto_json())\n\u001b[0;32m     10\u001b[0m quantized_model_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(quantized_model\u001b[39m.\u001b[39mto_json())\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m원본 모델 크기:\u001b[39m\u001b[39m\"\u001b[39m, original_model_size, \u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:5 out of the last 851 calls to <function Model.make_train_function.<locals>.train_function at 0x0000025911FA0D60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 851 calls to <function Model.make_train_function.<locals>.train_function at 0x0000025911FA0D60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3281 - accuracy: 0.9066 - val_loss: 0.1383 - val_accuracy: 0.9642\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9627 - val_loss: 0.0936 - val_accuracy: 0.9773\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0902 - accuracy: 0.9748 - val_loss: 0.0748 - val_accuracy: 0.9802\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0720 - accuracy: 0.9793 - val_loss: 0.0658 - val_accuracy: 0.9818\n",
      "Baseline test accuracy: 0.9790999889373779\n",
      "Saved baseline model to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpyyxcv088.h5\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
      " e_2 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
      " _3 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
      " oling2d_3 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 2028)              1         \n",
      " n_2 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                40572     \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40805 (159.41 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 20395 (79.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_25388\\3009220999.py:55: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 5s 9ms/step - loss: 0.1107 - accuracy: 0.9702 - val_loss: 0.1217 - val_accuracy: 0.9708\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9690 - val_loss: 0.0975 - val_accuracy: 0.9730\n",
      "Baseline test accuracy: 0.9714000225067139\n",
      "Pruned test accuracy: 0.9714000225067139\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_25388\\3009220999.py:114: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpbewu45db.h5\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_5 (Quantize  (None, 28, 28)            3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_reshape_2 (QuantizeW  (None, 28, 28, 1)         1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_conv2d_3 (QuantizeWr  (None, 26, 26, 12)        147       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_3 (Qua  (None, 13, 13, 12)        1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_2 (QuantizeW  (None, 2028)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_4 (QuantizeWra  (None, 10)                20295     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20448 (79.88 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 38 (152.00 Byte)\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 189ms/step - loss: 0.1067 - accuracy: 0.9756 - val_loss: 0.1495 - val_accuracy: 0.9600\n",
      "Baseline test accuracy: 0.9714000225067139\n",
      "Quantization-aware test accuracy: 0.9710999727249146\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpidtw2qdo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmpidtw2qdo\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model accuracy: 0.9711\n",
      "Original model size: 98928 bytes\n",
      "Pruned model size: 98928 bytes\n",
      "Quantized TFLite model size: 88200 bytes\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# get_gzipped_model_size 함수 정의\n",
    "def get_gzipped_model_size(file):\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the base model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the base digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=4,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "\n",
    "# Evaluate the baseline model\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "# Save the baseline model in HDF5 format\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n",
    "\n",
    "# Apply pruning to the base model\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1  # 10% of training set will be used for the validation set.\n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                             final_sparsity=0.80,\n",
    "                                                             begin_step=0,\n",
    "                                                             end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                      batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                      callbacks=callbacks)\n",
    "\n",
    "# Evaluate the baseline model and pruned model\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "_, pruned_model_accuracy = model_for_pruning.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Pruned test accuracy:', pruned_model_accuracy)\n",
    "\n",
    "# Strip pruning from the pruned model\n",
    "final_pruned_model = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# Additional part\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(final_pruned_model)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "\n",
    "# Quantization-aware training (QAT)\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for quantization-aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "                       loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()\n",
    "\n",
    "train_images_subset = train_images[0:1000]  # Subset of training data (for faster demonstration)\n",
    "train_labels_subset = train_labels[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                  batch_size=500, epochs=1, validation_split=0.1)\n",
    "\n",
    "# Evaluate the baseline model and quantization-aware model\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quantization-aware test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "# Convert the quantization-aware model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized TFLite model\n",
    "with open(\"quantized_model.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Evaluate the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "# Run inference on the test dataset\n",
    "quantized_model_accuracy = 0\n",
    "for test_image, test_label in zip(test_images, test_labels):\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "    predicted_label = np.argmax(output)\n",
    "    if predicted_label == test_label:\n",
    "        quantized_model_accuracy += 1\n",
    "\n",
    "quantized_model_accuracy /= len(test_images)\n",
    "\n",
    "print(\"Quantized TFLite model accuracy:\", quantized_model_accuracy)\n",
    "\n",
    "# Compare model sizes\n",
    "original_model_size = os.path.getsize(keras_file)\n",
    "pruned_model_size = os.path.getsize(pruned_keras_file)\n",
    "quantized_model_size = os.path.getsize(\"quantized_model.tflite\")\n",
    "\n",
    "print(\"Original model size:\", original_model_size, \"bytes\")\n",
    "print(\"Pruned model size:\", pruned_model_size, \"bytes\")\n",
    "print(\"Quantized TFLite model size:\", quantized_model_size, \"bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
