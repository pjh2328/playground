{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 및 모듈 설치\n",
    "import tempfile\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 크기 계산 함수\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "#모델 로드\n",
    "model = tf.keras.models.load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "로드된 모델의 정확도: 0.9566\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 테스트 데이터에 대한 예측 수행\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# 예측 결과를 실제 레이블과 비교하여 정확도 계산\n",
    "accuracy = (predictions.argmax(axis=1) == test_labels).mean()\n",
    "print(\"로드된 모델의 정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
      " e (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
      " oling2d (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 2028)              1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 10)                40572     \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40805 (159.41 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 20395 (79.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 5s 9ms/step - loss: 0.1561 - accuracy: 0.9599 - val_loss: 0.1356 - val_accuracy: 0.9687\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1480 - accuracy: 0.9615 - val_loss: 0.1120 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2715310a710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9566\n",
      "Pruned test accuracy: 0.9672999978065491\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "print('Baseline test accuracy:', accuracy)\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_for_pruning = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# 프루닝 모델 저장\n",
    "model_for_pruning.save(\"purned_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 233550 bytes\n",
      "Size of gzipped pruned Keras model: 25596 bytes\n"
     ]
    }
   ],
   "source": [
    "# 파일 크기를 정수로 변환하여 출력\n",
    "keras_file_size = int(get_gzipped_model_size(\"my_model.h5\"))\n",
    "pruned_keras_file_size = int(get_gzipped_model_size(\"purned_model.h5\"))\n",
    "print(\"Size of gzipped baseline Keras model: %d bytes\" % keras_file_size)\n",
    "print(\"Size of gzipped pruned Keras model: %d bytes\" % pruned_keras_file_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_1 (Quantize  (None, 28, 28)            3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_reshape (QuantizeWra  (None, 28, 28, 1)         1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_conv2d (QuantizeWrap  (None, 26, 26, 12)        147       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_max_pooling2d (Quant  (None, 13, 13, 12)        1         \n",
      " izeWrapperV2)                                                   \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 2028)              1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 10)                20295     \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20448 (79.88 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 38 (152.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 4s 37ms/step - loss: 0.1312 - accuracy: 0.9638 - val_loss: 0.0951 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29a5b46ed50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.fit(train_images, train_labels,\n",
    "                  batch_size=500, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q test accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "print('q test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp9r08_2gc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp9r08_2gc\\assets\n",
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#양자화 후 tf 라이트파일로 변환\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9652\n",
      "Quant TF test accuracy: 0.9652000069618225\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantized_tflite_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jay\\playground\\python\\atc\\Optimizayion\\test_3.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 양자화 모델 저장\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m _, quantized_keras_file \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mmkstemp(\u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39msave_model(quantized_tflite_model, quantized_keras_file, include_optimizer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSaved quantized Keras model to:\u001b[39m\u001b[39m'\u001b[39m, quantized_keras_file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'quantized_tflite_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 양자화 모델 저장\n",
    "_, quantized_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(quantized_tflite_model, quantized_keras_file, include_optimizer=False)\n",
    "print('Saved quantized Keras model to:', quantized_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프루닝 모델 저장\n",
    "q_aware_model.save(\"quantized_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp9eywa01t\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jay\\AppData\\Local\\Temp\\tmp9eywa01t\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create float TFLite model.\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "float_tflite_model = float_converter.convert()\n",
    "\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "\n",
    "with open(float_file, 'wb') as f:\n",
    "  f.write(float_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 233012 bytes\n",
      "Size of gzipped pruned Keras model: 25595 bytes\n",
      "Size of gzipped Quantized model: 183235 bytes\n"
     ]
    }
   ],
   "source": [
    "# 파일 크기를 정수로 변환하여 출력\n",
    "keras_file_size = int(get_gzipped_model_size(\"my_model.h5\"))\n",
    "pruned_keras_file_size = int(get_gzipped_model_size(\"purned_model.h5\"))\n",
    "quant_file_size = int(get_gzipped_model_size(\"quantized_model.h5\"))\n",
    "print(\"Size of gzipped baseline Keras model: %d bytes\" % keras_file_size)\n",
    "print(\"Size of gzipped pruned Keras model: %d bytes\" % pruned_keras_file_size)\n",
    "print(\"Size of gzipped Quantized model: %d bytes\" % quant_file_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'quantized_mdel.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jay\\playground\\python\\atc\\Optimizayion\\test_3.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m keras_file_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(get_gzipped_model_size(\u001b[39m\"\u001b[39m\u001b[39mmy_model.h5\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pruned_keras_file_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(get_gzipped_model_size(\u001b[39m\"\u001b[39m\u001b[39mpurned_model.h5\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m quant_file_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(get_gzipped_model_size(\u001b[39m\"\u001b[39;49m\u001b[39mquantized_mdel.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#압축률 = (압축 전 데이터 크기) / (압축 후 데이터 크기)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pruned_keras_compression_rate \u001b[39m=\u001b[39m ((keras_file_size \u001b[39m/\u001b[39m pruned_keras_file_size))\n",
      "\u001b[1;32mc:\\Users\\Jay\\playground\\python\\atc\\Optimizayion\\test_3.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m _, zipped_file \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mmkstemp(\u001b[39m'\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(zipped_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, compression\u001b[39m=\u001b[39mzipfile\u001b[39m.\u001b[39mZIP_DEFLATED) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   f\u001b[39m.\u001b[39;49mwrite(file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mgetsize(zipped_file)\n",
      "File \u001b[1;32mc:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1771\u001b[0m, in \u001b[0;36mZipFile.write\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_writing:\n\u001b[0;32m   1767\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt write to ZIP archive while an open writing handle exists\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m     )\n\u001b[1;32m-> 1771\u001b[0m zinfo \u001b[39m=\u001b[39m ZipInfo\u001b[39m.\u001b[39;49mfrom_file(filename, arcname,\n\u001b[0;32m   1772\u001b[0m                           strict_timestamps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strict_timestamps)\n\u001b[0;32m   1774\u001b[0m \u001b[39mif\u001b[39;00m zinfo\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m   1775\u001b[0m     zinfo\u001b[39m.\u001b[39mcompress_size \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:528\u001b[0m, in \u001b[0;36mZipInfo.from_file\u001b[1;34m(cls, filename, arcname, strict_timestamps)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    527\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(filename)\n\u001b[1;32m--> 528\u001b[0m st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(filename)\n\u001b[0;32m    529\u001b[0m isdir \u001b[39m=\u001b[39m stat\u001b[39m.\u001b[39mS_ISDIR(st\u001b[39m.\u001b[39mst_mode)\n\u001b[0;32m    530\u001b[0m mtime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mlocaltime(st\u001b[39m.\u001b[39mst_mtime)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다: 'quantized_mdel.h5'"
     ]
    }
   ],
   "source": [
    "# 파일 크기를 정수로 변환하여 출력\n",
    "keras_file_size = int(get_gzipped_model_size(\"my_model.h5\"))\n",
    "pruned_keras_file_size = int(get_gzipped_model_size(\"purned_model.h5\"))\n",
    "quant_file_size = int(get_gzipped_model_size(\"quantized_mdel.h5\"))\n",
    "#압축률 = (압축 전 데이터 크기) / (압축 후 데이터 크기)\n",
    "pruned_keras_compression_rate = ((keras_file_size / pruned_keras_file_size))\n",
    "quant_file_compression_rate = (keras_file_size / quant_file_size)\n",
    "#원본 모델 비교\n",
    "PADP = (baseline_model_accuracy - (baseline_model_accuracy - model_for_pruning_accuracy)) / baseline_model_accuracy * 100\n",
    "PADQ = (baseline_model_accuracy - (baseline_model_accuracy - q_aware_model_accuracy)) / baseline_model_accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "모델 사이즈\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keras_file_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jay\\playground\\python\\atc\\Optimizayion\\test_3.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m모델 사이즈\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-------------------------------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSize of gzipped baseline Keras model: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m keras_file_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSize of gzipped pruned Keras model: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m pruned_keras_file_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jay/playground/python/atc/Optimizayion/test_3.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSize of gzipped Quantized model: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m quant_file_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras_file_size' is not defined"
     ]
    }
   ],
   "source": [
    "print('-------------------------------------------------------------')\n",
    "print('모델 사이즈')\n",
    "print('-------------------------------------------------------------')\n",
    "print(\"Size of gzipped baseline Keras model: %d bytes\" % keras_file_size)\n",
    "print(\"Size of gzipped pruned Keras model: %d bytes\" % pruned_keras_file_size)\n",
    "print(\"Size of gzipped Quantized model: %d bytes\" % quant_file_size)\n",
    "print('-------------------------------------------------------------')\n",
    "print('모델 압축률')\n",
    "print('-------------------------------------------------------------')\n",
    "print(\"compression rate of pruned Keras model: %d\" % pruned_keras_compression_rate)\n",
    "print(\"compression rate of Quantized model: \", quant_file_compression_rate)\n",
    "print('-------------------------------------------------------------')\n",
    "print('모델 최적화 성능')\n",
    "print('-------------------------------------------------------------')\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_model_accuracy)\n",
    "print('-------------------------------------------------------------')\n",
    "print('모델 최적화 정확도 비교리포트')\n",
    "print('-------------------------------------------------------------')\n",
    "print('가지치기 비교 정확도 :', PADP)\n",
    "print('양자화 비교 정확도 :', PADQ)\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
