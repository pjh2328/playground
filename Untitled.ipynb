{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8255f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-model-optimization in /Users/jaehyeongpark/.local/lib/python3.11/site-packages (0.7.5)\n",
      "Requirement already satisfied: absl-py~=1.2 in /Users/jaehyeongpark/.local/lib/python3.11/site-packages (from tensorflow-model-optimization) (1.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /Users/jaehyeongpark/.local/lib/python3.11/site-packages (from tensorflow-model-optimization) (0.1.8)\n",
      "Requirement already satisfied: numpy~=1.23 in /Users/jaehyeongpark/anaconda3/lib/python3.11/site-packages (from tensorflow-model-optimization) (1.24.3)\n",
      "Requirement already satisfied: six~=1.14 in /Users/jaehyeongpark/anaconda3/lib/python3.11/site-packages (from tensorflow-model-optimization) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416ec6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 65s 4us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Build model...\n",
      "Model Sparsity Summary (sequential)\n",
      "--\n",
      "prune_low_magnitude_embedding: (embedding/embeddings:0, 7.812500000259348e-07)\n",
      "prune_low_magnitude_lstm: (lstm/lstm_cell/kernel:0, 0.0), (lstm/lstm_cell/recurrent_kernel:0, 0.0)\n",
      "prune_low_magnitude_dense: (dense/kernel:0, 0.0)\n",
      "\n",
      "\n",
      "Train...\n",
      "Epoch 1/3\n",
      "782/782 [==============================] - 66s 83ms/step - loss: 0.4258 - accuracy: 0.8075 - val_loss: 0.3431 - val_accuracy: 0.8515\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 0.2361 - accuracy: 0.9081 - val_loss: 0.3385 - val_accuracy: 0.8527\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 78s 100ms/step - loss: 0.1318 - accuracy: 0.9554 - val_loss: 0.4326 - val_accuracy: 0.8425\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.4326 - accuracy: 0.8425\n",
      "Model Sparsity Summary (sequential)\n",
      "--\n",
      "prune_low_magnitude_embedding: (embedding/embeddings:0, 0.68285)\n",
      "prune_low_magnitude_lstm: (lstm/lstm_cell/kernel:0, 0.6828460693359375), (lstm/lstm_cell/recurrent_kernel:0, 0.6828460693359375)\n",
      "prune_low_magnitude_dense: (dense/kernel:0, 0.6796875)\n",
      "\n",
      "\n",
      "Test score: 0.43263062834739685\n",
      "Test accuracy: 0.842519998550415\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Train a LSTM on the IMDB sentiment classification task.\n",
    "\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF+LogReg.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "\n",
    "keras = tf.keras\n",
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "def print_model_sparsity(pruned_model):\n",
    "  \"\"\"Prints sparsity for the pruned layers in the model.\n",
    "\n",
    "  Model Sparsity Summary\n",
    "  --\n",
    "  prune_lstm_1: (kernel, 0.5), (recurrent_kernel, 0.6)\n",
    "  prune_dense_1: (kernel, 0.5)\n",
    "\n",
    "  Args:\n",
    "    pruned_model: keras model to summarize.\n",
    "\n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  def _get_sparsity(weights):\n",
    "    return 1.0 - np.count_nonzero(weights) / float(weights.size)\n",
    "\n",
    "  print(\"Model Sparsity Summary ({})\".format(pruned_model.name))\n",
    "  print(\"--\")\n",
    "  for layer in pruned_model.layers:\n",
    "    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n",
    "      prunable_weights = layer.layer.get_prunable_weights()\n",
    "      if prunable_weights:\n",
    "        print(\"{}: {}\".format(\n",
    "            layer.name, \", \".join([\n",
    "                \"({}, {})\".format(weight.name,\n",
    "                                  str(_get_sparsity(K.get_value(weight))))\n",
    "                for weight in prunable_weights\n",
    "            ])))\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train,\n",
    " y_train), (x_test,\n",
    "            y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "print(\"Build model...\")\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(keras.layers.LSTM(128))  # try using a GRU instead, for fun\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.add(keras.layers.Activation(\"sigmoid\"))\n",
    "\n",
    "model = prune.prune_low_magnitude(model, pruning_schedule.PolynomialDecay(\n",
    "    initial_sparsity=0.3, final_sparsity=0.7, begin_step=1000, end_step=3000))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "print_model_sparsity(model)\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=3,\n",
    "          callbacks=[pruning_callbacks.UpdatePruningStep()],\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print_model_sparsity(model)\n",
    "print(\"Test score:\", score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb93231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
